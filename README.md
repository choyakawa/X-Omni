# ğŸ¨ X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image Generative Models Great Again

<p>
  <a href="https://x-omni-team.github.io">ğŸ  Project Page</a> |
  <a href="https://arxiv.org/pdf/2507.22058">ğŸ“„ Paper</a> |
  <a href="https://huggingface.co/collections/X-Omni/x-omni-models-6888aadcc54baad7997d7982">ğŸ¤— HuggingFace Model</a> |
  <a href="https://huggingface.co/collections/X-Omni/x-omni-spaces-6888c64f38446f1efc402de7">ğŸš€ HuggingFace Space</a> |
  <a href="#my-benchmark-section">ğŸ“Š LongText-Bench</a>
</p>


Official inference code and LongText-Bench benchmark for our paper **X-Omni**, a unified discrete autoregressive model for both image and language modalities.

## ğŸŒŸ Highlights

- **Unified Modeling Approach**: A discrete autoregressive model handling image and language modalities.
- **Superior Instruction Following**: Exceptional capability to follow complex instructions.
- **Superior Text Rendering**: Accurately render text in multiple languages, including both English and Chinese.
- **Arbitrary resolutions**: Produces aesthetically pleasing images at arbitrary resolutions.

## ğŸš€ Quick Start Guide

### Installation
```bash
conda create -n xomni python==3.12
conda activate xomni
pip install -r requirements.txt
pip install flash-attn --no-build-isolation 
```
If you get trouble in installing flash_attn, please refer to the offical repository: https://github.com/Dao-AILab/flash-attention. We recommand installing from .whl file like:
```bash
pip install flash_attn-2.7.3+cu12torch2.6cxx11abiFALSE-cp312-cp312-linux_x86_64.whl
```
### Inference
#### 1. Image Generation in English
```bash
PROMPT='A formal letter document with a professional tone. Create a document that includes  a section starting with "To, Mr. Edward Robertson," aligned to the left. Underneath, place the date "Date: 27th July 2025" also aligned to the left. Begin the body of the letter with "Dear Sir," indented slightly from the left margin. The first paragraph should state, "I am writing to you with intent of purchasing your property located at #765, Lincoln Street, New York." The second paragraph should read, "I want to propose a purchase price of $100,000 for your property. I am willing to pay you $20,000 as advance." The closing remarks should be, "Kindly let me know what do you think of the offer and we can make a few changes as per your requirements." followed by "Regards," and then "William Specter". Finally, add a logo with a feather graphic in the bottom right corner.'

IMG_PATH=/path/to/save/generation
FLUX_PATH=/path/to/FLUX.1-dev
python generate.py \
    --model_name_or_path X-Omni/X-Omni-En \
    --flux_model_name_or_path $FLUX_PATH \
    --prompt "$PROMPT" \
    --image-size 1152 1152 \
    --cfg-scale 1.0 \
    --min-p 0.03 \
    --seed 1234 \
    --output-path $IMG_PATH
```

#### 2. Image Generation in Chinese
```bash
PROMPT='ç”Ÿæˆä¸€å¼ é›ªä¸­çš„ç´«ç¦åŸå…¨æ™¯å°é¢å›¾ï¼Œä½œä¸ºåŒ—äº¬å†¬å­£æ—…æ¸¸æŒ‡å—çš„ä¸»é¢˜ã€‚ç”»é¢ä»¥è¿‘æ™¯æ„å›¾å±•ç°å»ºç­‘ï¼Œçº¢å¢™é‡‘ç“¦è¢«çš‘çš‘ç™½é›ªè¦†ç›–ï¼Œæœ±çº¢è‰²å®«å¢™ï¼Œé‡‘é»„è‰²ç“¦ç‰‡ä¸æ´ç™½é›ªè‰²å½¢æˆå¼ºçƒˆå¯¹æ¯”ï¼Œç‰ç’ƒç“¦é¡¶çš„ç§¯é›ªåœ¨é˜³å…‰ä¸‹æŠ˜å°„å‡ºæ™¶è¹å…‰æ³½ã€‚å‰æ™¯ä¸€æè…Šæ¢…èŠ±æ­£åœ¨ç››å¼€ï¼ŒèƒŒæ™¯ä¸ºç°è“è‰²å†¬æ—¥å¤©ç©ºï¼Œé£˜è½ç»†é›ªï¼Œè¿œå¤„è§’æ¥¼è½®å»“è‹¥éšè‹¥ç°ï¼Œå¢æ·»æœ¦èƒ§è¯—æ„æ„Ÿã€‚å›¾ç‰‡ä¸Šæœ‰æ ‡é¢˜â€œé›ªè½åŒ—å¹³Â·ç©¿è¶Š600å¹´â€ï¼Œå¦æœ‰å‰¯æ ‡é¢˜â€œåŒ—äº¬å¤å»ºç­‘é›ªæ™¯æ·±åº¦æ¸¸â€ã€‚æ–‡å­—è‰ºæœ¯æ„Ÿæå¼ºï¼Œä¸å›¾ç‰‡è‰¯å¥½èåˆèµ·æ¥'

IMG_PATH=/path/to/save/generation
FLUX_PATH=/path/to/FLUX.1-dev
python generate.py \
    --model_path X-Omni/X-Omni-Zh \
    --flux_model_name_or_path $FLUX_PATH \
    --prompt "$PROMPT" \
    --image-size 1152 1152 \
    --cfg-scale 1.0 \
    --min-p 0.03 \
    --seed 1234 \
    --output-path $IMG_PATH
```

#### 3. Multi-modal Chat
```bash
IMG_PATH=/path/to/your/input/image
PROMPT="Describe the image in detail."
FLUX_PATH=/path/to/FLUX.1-dev
python chat.py \
    --model_name_or_path X-Omni/X-Omni-En \
    --flux_model_name_or_path $FLUX_PATH \
    --prompt $PROMPT \
    --image-path $IMG_PATH
```

<a id="my-benchmark-section"></a>
## ğŸ“Š LongText-Bench 
[huggingface dataset](https://huggingface.co/datasets/X-Omni/LongText-Bench)

### 1. Install environment for Qwen2.5-VL
```bash
pip install transformers==4.52.0
pip install qwen_vl_utils
```
### 2. Sample results
Generate images according to prompts in 'text_prompts.jsonl' and 'text_prompts_zh.jsonl' and save according to the following structure:
```
â”œâ”€â”€ <SAMPLE_DIR>/
â”‚   â”œâ”€â”€ 0000_1.png
â”‚   â”œâ”€â”€ 0000_2.png
â”‚   â”œâ”€â”€ 0000_3.png
â”‚   â”œâ”€â”€ 0000_4.png
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ 0199_1.png
â”‚   â”œâ”€â”€ 0199_2.png
â”‚   â”œâ”€â”€ 0199_3.png
â”‚   â””â”€â”€ 0199_4.png
```
Make sure your generation results saved in the format: {prompt_id}_{repeat_id}.png, where prompt_id is provided in the prompt file and we uniformly sample each prompt four times to calculate the final results.
### 3. Evaluation
Here we provide a distributed evaluation script with torch DDP:
```bash
cd textbench
bash eval.sh
```
Replace MODE and SAMPLE_FOLDER in this script according to your generation results in step2. Feel free to modify the related parameters according to your requirements. 
## ğŸ“– Citation

If you find this project helpful for your research or use it in your own work, please cite our paper:
```bibtex
@article{geng2025xomni,
      author       = {Zigang Geng, Yibing Wang, Yeyao Ma, Chen Li, Yongming Rao, Shuyang Gu, Zhao Zhong, Qinglin Lu, Han Hu, Xiaosong Zhang, Linus, Di Wang and Jie Jiang},
      title        = {X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image Generative Models Great Again},
      journal      = {CoRR},
      volume       = {abs/2507.22058},
      year         = {2025},
}
```

---

## ğŸ“¬ Contact & Feedback

For questions or feedback, please don't hesitate to reach out:

- **Yibing Wang**: wangyibing18@mails.ucas.ac.cn
- **Tencent Hunyuan X Team**

If you are interested in joining us in working on **unified multimodal models**, please feel free to contact [Xiaosong Zhang](https://zhangxiaosong18.github.io).

---

â­ï¸ If this repository helped your research, please star ğŸŒŸ this repo ğŸ‘!
